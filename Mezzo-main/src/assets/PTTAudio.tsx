import { useState, useRef, useEffect } from 'react';
import { Mic, MicOff, Phone, PhoneOff, Volume2, VolumeX } from 'lucide-react';

interface PTTAudioProps {
    deviceId: string;
    channel: string;
    onAudioSend: (audioData: ArrayBuffer, isPrivate: boolean, targetId?: string, transcript?: string) => void;
    onSpeechToText?: (text: string) => void;  // èªéŸ³è½‰æ–‡å­—å›èª¿ï¼ˆå³æ™‚é¡¯ç¤ºç”¨ï¼‰
    ws?: WebSocket | null;  // WebSocket é€£ç·šï¼ˆç”¨æ–¼æ¥æ”¶ PTT æ¬Šé™è¨Šæ¯ï¼‰
}

interface AudioPacket {
    id: string;
    type: 'speech' | 'private';
    channel: string;
    from: string;
    audioData: string;  // base64
    timestamp: string;
    randomId?: string;
}

const PTTAudio = ({ deviceId, channel, onAudioSend, onSpeechToText, ws }: PTTAudioProps) => {
    // éŒ„éŸ³ç‹€æ…‹
    const [isRecording, setIsRecording] = useState(false);
    const [isMuted, setIsMuted] = useState(false);
    const [audioLevel, setAudioLevel] = useState(0);

    // PTT æ¶éº¥ç‹€æ…‹
    const [requestingMic, setRequestingMic] = useState(false);  // æ­£åœ¨è«‹æ±‚éº¥å…‹é¢¨
    const [hasPermission, setHasPermission] = useState(false);  // å·²ç²å¾—éº¥å…‹é¢¨æ¬Šé™
    const [currentSpeaker, setCurrentSpeaker] = useState<string | null>(null);  // ç•¶å‰é »é“èª°åœ¨èªªè©±

    // ç§äººé€šè©±ç‹€æ…‹
    const [privateCallActive, setPrivateCallActive] = useState(false);
    const [privateTargetId, setPrivateTargetId] = useState('');
    const [randomCallId, setRandomCallId] = useState('');

    // èªéŸ³è½‰æ–‡å­—ç‹€æ…‹
    const [autoSend, setAutoSend] = useState(false);  // è‡ªå‹•ç™¼é€é–‹é—œï¼ˆé è¨­é—œé–‰ï¼‰
    const [silenceThreshold, setSilenceThreshold] = useState(0.02);  // éœéŸ³é–¾å€¼
    const [silenceDuration, setSilenceDuration] = useState(1500);  // éœéŸ³æŒçºŒæ™‚é–“ (ms)
    const [speechRecognitionEnabled, setSpeechRecognitionEnabled] = useState(false);  // STT å¯ç”¨æ€§
    const [currentTranscript, setCurrentTranscript] = useState('');  // ç•¶å‰è­˜åˆ¥çš„æ–‡å­—

    // Refs
    const mediaRecorderRef = useRef<MediaRecorder | null>(null);
    const audioContextRef = useRef<AudioContext | null>(null);
    const analyserRef = useRef<AnalyserNode | null>(null);
    const audioChunksRef = useRef<Blob[]>([]);
    const streamRef = useRef<MediaStream | null>(null);
    const silenceTimerRef = useRef<NodeJS.Timeout | null>(null);
    const recognitionRef = useRef<any>(null);  // Web Speech API
    const isRecordingRef = useRef<boolean>(false);  // éŒ„éŸ³ç‹€æ…‹çš„ ref
    const finalTranscriptRef = useRef<string>('');  // ç´¯ç©çš„æœ€çµ‚è½‰éŒ„æ–‡å­—

    // åˆå§‹åŒ–éŸ³è¨Šä¸Šä¸‹æ–‡å’ŒèªéŸ³è­˜åˆ¥
    useEffect(() => {
        audioContextRef.current = new (window.AudioContext || (window as any).webkitAudioContext)();

        // åˆå§‹åŒ– Web Speech API (å¦‚æœç€è¦½å™¨æ”¯æ´)
        if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
            const SpeechRecognition = (window as any).webkitSpeechRecognition || (window as any).SpeechRecognition;
            recognitionRef.current = new SpeechRecognition();
            recognitionRef.current.continuous = true;
            recognitionRef.current.interimResults = true;
            recognitionRef.current.lang = 'zh-TW';  // ç¹é«”ä¸­æ–‡

            recognitionRef.current.onstart = () => {
                console.log('âœ… Speech recognition started successfully');
                setSpeechRecognitionEnabled(true);
            };

            recognitionRef.current.onend = () => {
                console.log('â¹ï¸ Speech recognition ended');
                setSpeechRecognitionEnabled(false);

                // å¦‚æœæ­£åœ¨éŒ„éŸ³ï¼Œè‡ªå‹•é‡æ–°å•Ÿå‹•èªéŸ³è­˜åˆ¥
                // é€™æ¨£å¯ä»¥ä¿æŒæŒçºŒè­˜åˆ¥
                if (isRecordingRef.current) {
                    setTimeout(() => {
                        try {
                            if (recognitionRef.current && isRecordingRef.current) {
                                recognitionRef.current.start();
                                console.log('ğŸ”„ Speech recognition auto-restarted');
                            }
                        } catch (err) {
                            console.warn('âš ï¸ Auto-restart failed:', err);
                        }
                    }, 100);
                }
            };

            recognitionRef.current.onresult = (event: any) => {
                // æ”¶é›†ç•¶å‰é€™æ¬¡çš„çµæœ
                let interimTranscript = '';

                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript;
                    if (event.results[i].isFinal) {
                        // ç´¯ç©æœ€çµ‚çµæœ
                        finalTranscriptRef.current += transcript;
                        console.log('âœ… Final result added:', transcript);
                    } else {
                        // è‡¨æ™‚çµæœ
                        interimTranscript += transcript;
                    }
                }

                // é¡¯ç¤ºçš„æ–‡å­— = å·²ç¢ºèªçš„æ–‡å­— + è‡¨æ™‚æ–‡å­—
                const displayText = finalTranscriptRef.current + interimTranscript;
                console.log('ğŸ¤ Speech recognized:', {
                    finalAccumulated: finalTranscriptRef.current || '(none)',
                    interim: interimTranscript || '(none)',
                    display: displayText
                });

                // å³æ™‚æ›´æ–°é¡¯ç¤º
                setCurrentTranscript(displayText);

                // é€šçŸ¥çˆ¶çµ„ä»¶ï¼ˆåƒ…ç”¨æ–¼å³æ™‚é¡¯ç¤ºï¼Œä¸å½±éŸ¿ç™¼é€ï¼‰
                if (onSpeechToText && displayText) {
                    onSpeechToText(displayText);
                }
            };

            recognitionRef.current.onerror = (event: any) => {
                console.error('âŒ Speech recognition error:', event.error);
                if (event.error === 'not-allowed') {
                    alert('è«‹å…è¨±éº¥å…‹é¢¨æ¬Šé™ä»¥ä½¿ç”¨èªéŸ³è½‰æ–‡å­—åŠŸèƒ½');
                }
            };

            console.log('âœ… Speech Recognition API initialized');
        } else {
            console.warn('âš ï¸ Web Speech API not supported in this browser');
        }

        return () => {
            if (audioContextRef.current) {
                audioContextRef.current.close();
            }
            if (recognitionRef.current) {
                recognitionRef.current.stop();
            }
        };
    }, [onSpeechToText]);

    // ç›£æ§éŸ³è¨Šé›»å¹³å’ŒéœéŸ³åµæ¸¬
    useEffect(() => {
        if (!isRecording || !analyserRef.current) return;

        const dataArray = new Uint8Array(analyserRef.current.frequencyBinCount);
        const updateLevel = () => {
            if (!analyserRef.current) return;

            analyserRef.current.getByteFrequencyData(dataArray);
            const average = dataArray.reduce((a, b) => a + b) / dataArray.length;
            const level = average / 255;
            setAudioLevel(level);

            // éœéŸ³åµæ¸¬ (è‡ªå‹•æ–·å¥)
            if (autoSend && !privateCallActive) {
                if (level < silenceThreshold) {
                    // åµæ¸¬åˆ°éœéŸ³ï¼Œé–‹å§‹è¨ˆæ™‚
                    if (!silenceTimerRef.current) {
                        silenceTimerRef.current = setTimeout(() => {
                            console.log('ğŸ”‡ Silence detected, auto-sending audio chunk...');
                            stopGroupRecording();  // è‡ªå‹•åœæ­¢ä¸¦ç™¼é€
                        }, silenceDuration);
                    }
                } else {
                    // æœ‰è²éŸ³ï¼Œæ¸…é™¤è¨ˆæ™‚å™¨
                    if (silenceTimerRef.current) {
                        clearTimeout(silenceTimerRef.current);
                        silenceTimerRef.current = null;
                    }
                }
            }

            if (isRecording) {
                requestAnimationFrame(updateLevel);
            }
        };

        updateLevel();

        return () => {
            if (silenceTimerRef.current) {
                clearTimeout(silenceTimerRef.current);
                silenceTimerRef.current = null;
            }
        };
    }, [isRecording, autoSend, silenceThreshold, silenceDuration, privateCallActive]);

    // ç›£è½ WebSocket çš„ PTT æ¬Šé™è¨Šæ¯
    useEffect(() => {
        if (!ws) return;

        const handleMessage = (event: MessageEvent) => {
            try {
                const data = JSON.parse(event.data);

                // æ”¶åˆ°å…è¨±ç™¼è¨€
                if (data.type === 'ptt_speech_allow' && data.channel === channel) {
                    console.log('âœ… PTT permission granted');
                    setRequestingMic(false);
                    setHasPermission(true);
                    // ç«‹å³é–‹å§‹éŒ„éŸ³
                    actuallyStartRecording();
                }

                // æ”¶åˆ°æ‹’çµ•ç™¼è¨€
                if (data.type === 'ptt_speech_deny' && data.channel === channel) {
                    console.log('ğŸš« PTT permission denied:', data.reason);
                    setRequestingMic(false);
                    setHasPermission(false);
                    alert(`ç„¡æ³•å–å¾—éº¥å…‹é¢¨ï¼š${data.reason || 'å·²æœ‰äººåœ¨ä½¿ç”¨'}`);
                }

                // æ”¶åˆ°è«‹æ±‚å·²ç™¼é€é€šçŸ¥
                if (data.type === 'ptt_mic_request_sent' && data.channel === channel) {
                    console.log(`â³ Mic request sent to ${data.currentSpeaker}, waiting for response...`);
                    // ä¿æŒ requestingMic ç‹€æ…‹ï¼Œé¡¯ç¤ºç­‰å¾…ä¸­
                }

                // æ”¶åˆ°æ¶éº¥è«‹æ±‚ï¼ˆæœ‰äººæƒ³è¦æ¶æˆ‘çš„éº¥å…‹é¢¨ï¼‰
                if (data.type === 'ptt_mic_request' && data.channel === channel && data.currentSpeaker === deviceId) {
                    console.log(`ğŸ”” Mic request from ${data.requester}`);
                    const accept = window.confirm(`${data.requester} æƒ³è¦ç™¼è¨€ï¼Œæ˜¯å¦è®“å‡ºéº¥å…‹é¢¨ï¼Ÿ`);

                    // ç™¼é€å›æ‡‰
                    sendMicResponse(data.requester, accept);

                    if (accept) {
                        // åœæ­¢è‡ªå·±çš„éŒ„éŸ³
                        stopGroupRecording();
                    }
                }

                // æ”¶åˆ°èªªè©±è€…æ›´æ–°ï¼ˆèª°åœ¨èªªè©±ï¼‰
                if (data.type === 'ptt_speaker_update' && data.channel === channel) {
                    if (data.action === 'start') {
                        setCurrentSpeaker(data.speaker);
                        console.log(`ğŸ™ï¸ ${data.speaker} is now speaking`);
                    } else if (data.action === 'stop') {
                        setCurrentSpeaker(null);
                        console.log(`ğŸ›‘ ${data.previousSpeaker} stopped speaking`);
                    }
                }
            } catch (error) {
                // Ignore parse errors for non-JSON messages
            }
        };

        ws.addEventListener('message', handleMessage);

        return () => {
            ws.removeEventListener('message', handleMessage);
        };
    }, [ws, channel, deviceId]);

    // è«‹æ±‚ç™¼è¨€æ¬Šé™ï¼ˆç¾¤çµ„é€šè©±çš„æ¶éº¥æ©Ÿåˆ¶ï¼‰
    const startGroupRecording = async () => {
        try {
            const API_BASE = window.location.hostname === 'localhost' ? 'http://localhost:4000' : `http://${window.location.hostname}:4000`;

            console.log('ğŸ™ï¸ Requesting PTT permission...');
            setRequestingMic(true);

            // å»ºç«‹ PTT_MSG_TYPE_SPEECH_START è¨Šæ¯
            const tag = 'PTT_MSG_TYPE_SPEECH_START';
            const data = '';  // ç„¡éœ€é¡å¤–è³‡æ–™

            // å»ºç«‹ PTT è¨Šæ¯æ ¼å¼: Tag(32) + UUID(128) + Data
            const tagBuffer = new Uint8Array(32);
            const tagBytes = new TextEncoder().encode(tag);
            tagBuffer.set(tagBytes.slice(0, 32));

            const uuidBuffer = new Uint8Array(128);
            const uuidBytes = new TextEncoder().encode(deviceId);
            uuidBuffer.set(uuidBytes.slice(0, 128));

            const dataBytes = new TextEncoder().encode(data);
            const combined = new Uint8Array(160 + dataBytes.length);
            combined.set(tagBuffer, 0);
            combined.set(uuidBuffer, 32);
            combined.set(dataBytes, 160);

            // ç™¼é€è«‹æ±‚åˆ°å¾Œç«¯
            const response = await fetch(`${API_BASE}/ptt/publish`, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    topic: `/WJI/PTT/${channel}/CHANNEL_ANNOUNCE`,
                    message: Array.from(combined),
                    encoding: 'binary'
                })
            });

            if (!response.ok) {
                setRequestingMic(false);
                alert('è«‹æ±‚ç™¼è¨€æ¬Šé™å¤±æ•—');
            }

            // ç­‰å¾… WebSocket å›æ‡‰ (åœ¨ useEffect ä¸­è™•ç†)
            console.log('â³ Waiting for PTT permission response...');

        } catch (error) {
            console.error('âŒ Failed to request PTT permission:', error);
            setRequestingMic(false);
            alert('ç„¡æ³•è«‹æ±‚ç™¼è¨€æ¬Šé™');
        }
    };

    // ç™¼é€æ¶éº¥å›æ‡‰ï¼ˆåŒæ„æˆ–æ‹’çµ•è®“å‡ºéº¥å…‹é¢¨ï¼‰
    const sendMicResponse = async (requesterUUID: string, accept: boolean) => {
        try {
            const API_BASE = window.location.hostname === 'localhost' ? 'http://localhost:4000' : `http://${window.location.hostname}:4000`;

            const tag = 'PTT_MSG_TYPE_MIC_RESPONSE';
            const data = `${requesterUUID},${accept ? 'accept' : 'deny'}`;

            const tagBuffer = new Uint8Array(32);
            const tagBytes = new TextEncoder().encode(tag);
            tagBuffer.set(tagBytes.slice(0, 32));

            const uuidBuffer = new Uint8Array(128);
            const uuidBytes = new TextEncoder().encode(deviceId);
            uuidBuffer.set(uuidBytes.slice(0, 128));

            const dataBytes = new TextEncoder().encode(data);
            const combined = new Uint8Array(160 + dataBytes.length);
            combined.set(tagBuffer, 0);
            combined.set(uuidBuffer, 32);
            combined.set(dataBytes, 160);

            await fetch(`${API_BASE}/ptt/publish`, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    topic: `/WJI/PTT/${channel}/CHANNEL_ANNOUNCE`,
                    message: Array.from(combined),
                    encoding: 'binary'
                })
            });

            console.log(`ğŸ“¤ Mic response sent: ${accept ? 'accept' : 'deny'} to ${requesterUUID}`);
        } catch (error) {
            console.error('âŒ Failed to send mic response:', error);
        }
    };

    // å¯¦éš›é–‹å§‹éŒ„éŸ³ï¼ˆå…§éƒ¨å‡½æ•¸ï¼Œæ¬Šé™ç²å¾—å¾Œèª¿ç”¨ï¼‰
    const actuallyStartRecording = async () => {
        try {
            // æ¸…ç©ºä¹‹å‰ç´¯ç©çš„è½‰éŒ„æ–‡å­—
            finalTranscriptRef.current = '';
            setCurrentTranscript('');

            const stream = await navigator.mediaDevices.getUserMedia({
                audio: {
                    echoCancellation: true,
                    noiseSuppression: true,
                    autoGainControl: true,
                    sampleRate: 16000  // 16kHz é©åˆèªéŸ³
                }
            });

            streamRef.current = stream;

            // è¨­ç½®éŸ³è¨Šåˆ†æå™¨
            if (audioContextRef.current) {
                const source = audioContextRef.current.createMediaStreamSource(stream);
                analyserRef.current = audioContextRef.current.createAnalyser();
                analyserRef.current.fftSize = 256;
                source.connect(analyserRef.current);
            }

            // å‰µå»º MediaRecorder
            const mediaRecorder = new MediaRecorder(stream, {
                mimeType: 'audio/webm;codecs=opus'
            });

            mediaRecorderRef.current = mediaRecorder;
            audioChunksRef.current = [];

            mediaRecorder.ondataavailable = (event) => {
                if (event.data.size > 0) {
                    audioChunksRef.current.push(event.data);
                }
            };

            mediaRecorder.onstop = async () => {
                const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
                const arrayBuffer = await audioBlob.arrayBuffer();

                // ä½¿ç”¨ç•¶å‰é¡¯ç¤ºçš„æ–‡å­—ï¼ˆåŒ…å«æœ€çµ‚å’Œè‡¨æ™‚çµæœï¼‰
                // å› ç‚ºæœ‰æ™‚å€™èªéŸ³è­˜åˆ¥é‚„æ²’ä¾†å¾—åŠæ¨™è¨˜ç‚º final å°±è¢«åœæ­¢äº†
                const textToSend = currentTranscript || finalTranscriptRef.current;
                console.log('ğŸ“ Sending audio with transcript:', {
                    currentTranscript,
                    finalTranscript: finalTranscriptRef.current,
                    willSend: textToSend || '(empty)'
                });
                onAudioSend(arrayBuffer, false, undefined, textToSend);

                // æ¸…ç©ºè½‰éŒ„æ–‡å­—
                setCurrentTranscript('');
                finalTranscriptRef.current = '';

                // æ¸…ç†
                audioChunksRef.current = [];
                if (streamRef.current) {
                    streamRef.current.getTracks().forEach(track => track.stop());
                    streamRef.current = null;
                }
            };

            mediaRecorder.start(100);  // æ¯ 100ms æ”¶é›†ä¸€æ¬¡æ•¸æ“š
            setIsRecording(true);
            isRecordingRef.current = true;

            // å•Ÿå‹•èªéŸ³è­˜åˆ¥
            if (recognitionRef.current) {
                try {
                    // å…ˆå˜—è©¦åœæ­¢ï¼ˆå¦‚æœæ­£åœ¨é‹è¡Œï¼‰
                    if (speechRecognitionEnabled) {
                        recognitionRef.current.stop();
                    }
                    // ç­‰å¾…ä¸€ä¸‹å†å•Ÿå‹•
                    setTimeout(() => {
                        try {
                            recognitionRef.current.start();
                            console.log('ğŸ¤ Starting speech recognition...');
                        } catch (err) {
                            console.warn('âš ï¸ Speech recognition start failed:', err);
                        }
                    }, 100);
                } catch (err) {
                    console.warn('âš ï¸ Speech recognition stop failed:', err);
                }
            } else {
                console.warn('âš ï¸ Speech recognition not initialized');
            }

            console.log('ğŸ™ï¸ Started group recording');

        } catch (error) {
            console.error('âŒ Failed to start recording:', error);
            alert('ç„¡æ³•è¨ªå•éº¥å…‹é¢¨ï¼Œè«‹ç¢ºä¿å·²æˆäºˆæ¬Šé™');
        }
    };

    // åœæ­¢ç¾¤çµ„éŒ„éŸ³
    const stopGroupRecording = async () => {
        if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
            mediaRecorderRef.current.stop();
            setIsRecording(false);
            isRecordingRef.current = false;
            setAudioLevel(0);
            setHasPermission(false);  // é‡‹æ”¾éº¥å…‹é¢¨æ¬Šé™

            // åœæ­¢èªéŸ³è­˜åˆ¥
            if (recognitionRef.current) {
                try {
                    recognitionRef.current.stop();
                    console.log('ğŸ¤ Speech recognition stopped');
                } catch (err) {
                    console.warn('âš ï¸ Speech recognition stop failed:', err);
                }
            }

            // æ¸…é™¤éœéŸ³è¨ˆæ™‚å™¨
            if (silenceTimerRef.current) {
                clearTimeout(silenceTimerRef.current);
                silenceTimerRef.current = null;
            }

            // ç™¼é€ PTT_MSG_TYPE_SPEECH_STOP é€šçŸ¥å¾Œç«¯é‡‹æ”¾éº¥å…‹é¢¨
            try {
                const API_BASE = window.location.hostname === 'localhost' ? 'http://localhost:4000' : `http://${window.location.hostname}:4000`;

                const tag = 'PTT_MSG_TYPE_SPEECH_STOP';
                const data = '';

                const tagBuffer = new Uint8Array(32);
                const tagBytes = new TextEncoder().encode(tag);
                tagBuffer.set(tagBytes.slice(0, 32));

                const uuidBuffer = new Uint8Array(128);
                const uuidBytes = new TextEncoder().encode(deviceId);
                uuidBuffer.set(uuidBytes.slice(0, 128));

                const dataBytes = new TextEncoder().encode(data);
                const combined = new Uint8Array(160 + dataBytes.length);
                combined.set(tagBuffer, 0);
                combined.set(uuidBuffer, 32);
                combined.set(dataBytes, 160);

                await fetch(`${API_BASE}/ptt/publish`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        topic: `/WJI/PTT/${channel}/CHANNEL_ANNOUNCE`,
                        message: Array.from(combined),
                        encoding: 'binary'
                    })
                });

                console.log('ğŸ›‘ PTT_MSG_TYPE_SPEECH_STOP sent');
            } catch (error) {
                console.error('âŒ Failed to send SPEECH_STOP:', error);
            }

            console.log('ğŸ™ï¸ Stopped group recording');
        }
    };

    // ç™¼é€ç§äººé€šè©±è«‹æ±‚ï¼ˆæ¡æ‰‹ï¼‰
    const startPrivateCall = async () => {
        if (!privateTargetId.trim()) {
            alert('è«‹è¼¸å…¥ç›®æ¨™è¨­å‚™ ID');
            return;
        }

        // ç”Ÿæˆéš¨æ©Ÿé€šè©± Topic ID
        const callTopicId = `PRIVATE-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
        setRandomCallId(callTopicId);

        try {
            // ç™¼é€ PRIVATE_SPK_REQ æ¡æ‰‹è«‹æ±‚
            const API_BASE = window.location.hostname === 'localhost' ? 'http://localhost:4000' : `http://${window.location.hostname}:4000`;

            // å»ºç«‹æ¡æ‰‹è¨Šæ¯: Tag + UUID + Data
            const tag = 'PRIVATE_SPK_REQ';
            const data = `${privateTargetId},${callTopicId}`;  // "TargetUUID,PrivateTopicID"

            const tagBuffer = new Uint8Array(32);
            const tagBytes = new TextEncoder().encode(tag);
            tagBuffer.set(tagBytes.slice(0, 32));

            const uuidBuffer = new Uint8Array(128);
            const uuidBytes = new TextEncoder().encode(deviceId);
            uuidBuffer.set(uuidBytes.slice(0, 128));

            const dataBytes = new TextEncoder().encode(data);
            const combined = new Uint8Array(160 + dataBytes.length);
            combined.set(tagBuffer, 0);
            combined.set(uuidBuffer, 32);
            combined.set(dataBytes, 160);

            const response = await fetch(`${API_BASE}/ptt/publish`, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    topic: `/WJI/PTT/${channel}/CHANNEL_ANNOUNCE`,
                    message: Array.from(combined),
                    encoding: 'binary'
                })
            });

            if (response.ok) {
                setPrivateCallActive(true);
                console.log(`ğŸ“ Private call request sent: ${deviceId} â†’ ${privateTargetId} (Topic: ${callTopicId})`);
                // TODO: ç­‰å¾…å°æ–¹æ¥å—å¾Œæ‰é–‹å§‹éŒ„éŸ³
                // ç›®å‰å…ˆç›´æ¥é€²å…¥é€šè©±ç‹€æ…‹ï¼ˆç°¡åŒ–ç‰ˆï¼‰
            } else {
                throw new Error('Failed to send call request');
            }

        } catch (error) {
            console.error('âŒ Failed to start private call:', error);
            alert('ç™¼é€é€šè©±è«‹æ±‚å¤±æ•—');
            setPrivateCallActive(false);
            setRandomCallId('');
        }
    };

    // çµæŸç§äººé€šè©±
    const endPrivateCall = async () => {
        if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
            mediaRecorderRef.current.stop();
        }
        setIsRecording(false);
        isRecordingRef.current = false;

        // ç™¼é€ PRIVATE_SPK_STOP é€šçŸ¥å°æ–¹
        try {
            const API_BASE = window.location.hostname === 'localhost' ? 'http://localhost:4000' : `http://${window.location.hostname}:4000`;

            const tag = 'PRIVATE_SPK_STOP';
            const data = privateTargetId;  // TargetUUID

            const tagBuffer = new Uint8Array(32);
            const tagBytes = new TextEncoder().encode(tag);
            tagBuffer.set(tagBytes.slice(0, 32));

            const uuidBuffer = new Uint8Array(128);
            const uuidBytes = new TextEncoder().encode(deviceId);
            uuidBuffer.set(uuidBytes.slice(0, 128));

            const dataBytes = new TextEncoder().encode(data);
            const combined = new Uint8Array(160 + dataBytes.length);
            combined.set(tagBuffer, 0);
            combined.set(uuidBuffer, 32);
            combined.set(dataBytes, 160);

            await fetch(`${API_BASE}/ptt/publish`, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    topic: `/WJI/PTT/${channel}/CHANNEL_ANNOUNCE`,
                    message: Array.from(combined),
                    encoding: 'binary'
                })
            });

            console.log(`ğŸ“ Private call stop sent to ${privateTargetId}`);
        } catch (error) {
            console.error('âŒ Failed to send call stop:', error);
        }

        setPrivateCallActive(false);
        setRandomCallId('');
        setAudioLevel(0);
        console.log('ğŸ“ Ended private call');
    };

    // åˆ‡æ›éœéŸ³
    const toggleMute = () => {
        if (streamRef.current) {
            streamRef.current.getAudioTracks().forEach(track => {
                track.enabled = isMuted;
            });
            setIsMuted(!isMuted);
        }
    };

    return (
        <div className="space-y-4">
            {/* ç¾¤çµ„èªéŸ³ PTT */}
            <div className="bg-white rounded-lg border border-gray-200 p-4">
                <h4 className="font-semibold mb-3 flex items-center gap-2">
                    <Mic className="w-4 h-4" />
                    ç¾¤çµ„èªéŸ³ PTT
                </h4>

                <div className="space-y-3">
                    {/* ç•¶å‰é »é“ */}
                    <div className="text-sm text-gray-600">
                        ç•¶å‰é »é“: <span className="font-medium text-gray-900">{channel}</span>
                    </div>

                    {/* é »é“ç‹€æ…‹é¡¯ç¤º */}
                    {isRecording ? (
                        // è‡ªå·±æ­£åœ¨éŒ„éŸ³
                        <div className="bg-red-50 border border-red-200 rounded-lg p-2">
                            <div className="flex items-center gap-2">
                                <Mic className="w-4 h-4 text-red-600 animate-pulse" />
                                <div className="text-sm">
                                    <span className="font-medium text-red-900">æ‚¨æ­£åœ¨ç™¼è©±ä¸­</span>
                                </div>
                            </div>
                        </div>
                    ) : currentSpeaker && currentSpeaker !== deviceId ? (
                        // å…¶ä»–äººæ­£åœ¨ç™¼è©±
                        <div className="bg-yellow-50 border border-yellow-200 rounded-lg p-2">
                            <div className="flex items-center gap-2">
                                <Mic className="w-4 h-4 text-yellow-600 animate-pulse" />
                                <div className="text-sm">
                                    <span className="font-medium text-yellow-900">{currentSpeaker}</span>
                                    <span className="text-yellow-700"> æ­£åœ¨ç™¼è©±ä¸­</span>
                                </div>
                            </div>
                        </div>
                    ) : (
                        // é »é“ç©ºé–’
                        <div className="bg-green-50 border border-green-200 rounded-lg p-2">
                            <div className="flex items-center gap-2">
                                <Mic className="w-4 h-4 text-green-600" />
                                <div className="text-sm text-green-700">
                                    é »é“ç©ºé–’ - å¯ä»¥ç™¼è©±
                                </div>
                            </div>
                        </div>
                    )}

                    {/* è«‹æ±‚ä¸­ç‹€æ…‹ - åªåœ¨è«‹æ±‚éšæ®µä½†é‚„æ²’é–‹å§‹éŒ„éŸ³æ™‚é¡¯ç¤º */}
                    {requestingMic && !isRecording && (
                        <div className="bg-blue-50 border border-blue-200 rounded-lg p-2">
                            <div className="flex items-center gap-2">
                                <div className="w-4 h-4 border-2 border-blue-600 border-t-transparent rounded-full animate-spin"></div>
                                <div className="text-sm text-blue-700">
                                    æ­£åœ¨è«‹æ±‚ç™¼è©±æ¬Šé™...
                                </div>
                            </div>
                        </div>
                    )}

                    {/* PTT æŒ‰éˆ• - æ”¹ç‚ºé»æ“Šé–‹å§‹/çµæŸ */}
                    <button
                        onClick={() => {
                            if (isRecording && !privateCallActive) {
                                stopGroupRecording();
                            } else if (!privateCallActive) {
                                startGroupRecording();
                            }
                        }}
                        disabled={privateCallActive}
                        className={`w-full py-4 rounded-lg font-semibold transition-all ${
                            isRecording && !privateCallActive
                                ? 'bg-red-600 text-white shadow-lg scale-105'
                                : 'bg-blue-600 text-white hover:bg-blue-700'
                        } disabled:bg-gray-300 disabled:cursor-not-allowed`}
                    >
                        {isRecording && !privateCallActive ? (
                            <div className="flex items-center justify-center gap-2">
                                <Mic className="w-5 h-5 animate-pulse" />
                                <span>é»æ“Šåœæ­¢ç™¼è©±</span>
                            </div>
                        ) : (
                            <div className="flex items-center justify-center gap-2">
                                <Mic className="w-5 h-5" />
                                <span>é»æ“Šé–‹å§‹ç™¼è©± (PTT)</span>
                            </div>
                        )}
                    </button>

                    {/* éŸ³è¨Šé›»å¹³æŒ‡ç¤ºå™¨ */}
                    {isRecording && !privateCallActive && (
                        <div className="space-y-1">
                            <div className="text-xs text-gray-600">éŸ³è¨Šé›»å¹³</div>
                            <div className="h-2 bg-gray-200 rounded-full overflow-hidden">
                                <div
                                    className="h-full bg-green-500 transition-all duration-100"
                                    style={{ width: `${audioLevel * 100}%` }}
                                />
                            </div>
                        </div>
                    )}

                    {/* å³æ™‚è½‰éŒ„æ–‡å­—é¡¯ç¤º */}
                    {isRecording && currentTranscript && (
                        <div className="bg-blue-50 border border-blue-200 rounded p-2">
                            <div className="text-xs text-gray-600 mb-1">æ­£åœ¨è­˜åˆ¥:</div>
                            <div className="text-sm text-blue-900 italic">{currentTranscript}</div>
                        </div>
                    )}

                    {/* éœéŸ³æŒ‰éˆ• */}
                    <button
                        onClick={toggleMute}
                        disabled={!isRecording}
                        className={`w-full px-4 py-2 rounded-lg text-sm font-medium transition-colors ${
                            isMuted
                                ? 'bg-red-100 text-red-700 border border-red-300'
                                : 'bg-gray-100 text-gray-700 border border-gray-300'
                        } disabled:opacity-50 disabled:cursor-not-allowed`}
                    >
                        {isMuted ? (
                            <span className="flex items-center justify-center gap-2">
                                <VolumeX className="w-4 h-4" />
                                å·²éœéŸ³
                            </span>
                        ) : (
                            <span className="flex items-center justify-center gap-2">
                                <Volume2 className="w-4 h-4" />
                                å–æ¶ˆéœéŸ³
                            </span>
                        )}
                    </button>
                </div>
            </div>

            {/* ç§äººé€šè©± */}
            <div className="bg-white rounded-lg border border-gray-200 p-4">
                <h4 className="font-semibold mb-3 flex items-center gap-2">
                    <Phone className="w-4 h-4" />
                    ç§äººé€šè©±
                </h4>

                <div className="space-y-3">
                    {!privateCallActive ? (
                        <>
                            <input
                                type="text"
                                value={privateTargetId}
                                onChange={(e) => setPrivateTargetId(e.target.value)}
                                placeholder="è¼¸å…¥ç›®æ¨™è¨­å‚™ ID"
                                className="w-full px-3 py-2 border border-gray-300 rounded-lg text-sm focus:ring-2 focus:ring-blue-500"
                            />
                            <button
                                onClick={startPrivateCall}
                                disabled={isRecording || !privateTargetId.trim()}
                                className="w-full px-4 py-2 bg-green-600 text-white rounded-lg hover:bg-green-700 disabled:bg-gray-300 disabled:cursor-not-allowed transition-colors"
                            >
                                <span className="flex items-center justify-center gap-2">
                                    <Phone className="w-4 h-4" />
                                    ç™¼èµ·é€šè©±
                                </span>
                            </button>
                        </>
                    ) : (
                        <div className="space-y-3">
                            <div className="text-sm">
                                <div className="text-gray-600">é€šè©±ä¸­</div>
                                <div className="font-medium">â†’ {privateTargetId}</div>
                                <div className="text-xs text-gray-500 mt-1">
                                    Call ID: {randomCallId}
                                </div>
                            </div>

                            {/* éŸ³è¨Šé›»å¹³ */}
                            {isRecording && (
                                <div className="space-y-1">
                                    <div className="text-xs text-gray-600">éŸ³è¨Šé›»å¹³</div>
                                    <div className="h-2 bg-gray-200 rounded-full overflow-hidden">
                                        <div
                                            className="h-full bg-blue-500 transition-all duration-100"
                                            style={{ width: `${audioLevel * 100}%` }}
                                        />
                                    </div>
                                </div>
                            )}

                            <button
                                onClick={endPrivateCall}
                                className="w-full px-4 py-2 bg-red-600 text-white rounded-lg hover:bg-red-700 transition-colors"
                            >
                                <span className="flex items-center justify-center gap-2">
                                    <PhoneOff className="w-4 h-4" />
                                    çµæŸé€šè©±
                                </span>
                            </button>
                        </div>
                    )}
                </div>
            </div>

            {/* èªéŸ³è½‰æ–‡å­—å’Œè‡ªå‹•æ–·å¥è¨­å®š */}
            <div className="bg-white rounded-lg border border-gray-200 p-4">
                <h4 className="font-semibold mb-3 flex items-center justify-between">
                    é€²éšè¨­å®š
                    {speechRecognitionEnabled && (
                        <span className="text-xs text-green-600 flex items-center gap-1">
                            <span className="w-2 h-2 bg-green-600 rounded-full animate-pulse"></span>
                            STT é‹è¡Œä¸­
                        </span>
                    )}
                </h4>

                <div className="space-y-3">
                    {/* èªéŸ³è­˜åˆ¥ç‹€æ…‹ */}
                    <div className="bg-blue-50 border border-blue-200 rounded p-2 text-xs">
                        <div className="font-semibold mb-1">èªéŸ³è½‰æ–‡å­—ç‹€æ…‹</div>
                        <div className="text-gray-700">
                            {speechRecognitionEnabled ? (
                                <span className="text-green-600">âœ… èªéŸ³è­˜åˆ¥å·²å•Ÿå‹•</span>
                            ) : (
                                <span className="text-gray-500">â¸ï¸ èªéŸ³è­˜åˆ¥æœªå•Ÿå‹•</span>
                            )}
                        </div>
                    </div>

                    {/* è‡ªå‹•ç™¼é€é–‹é—œ */}
                    <div className="flex items-center justify-between">
                        <label className="text-sm text-gray-700">è‡ªå‹•æ–·å¥ç™¼é€</label>
                        <input
                            type="checkbox"
                            checked={autoSend}
                            onChange={(e) => setAutoSend(e.target.checked)}
                            className="w-4 h-4"
                        />
                    </div>

                    {/* éœéŸ³é–¾å€¼ */}
                    <div>
                        <label className="text-sm text-gray-700 block mb-1">
                            éœéŸ³é–¾å€¼: {(silenceThreshold * 100).toFixed(0)}%
                        </label>
                        <input
                            type="range"
                            min="0"
                            max="0.1"
                            step="0.01"
                            value={silenceThreshold}
                            onChange={(e) => setSilenceThreshold(parseFloat(e.target.value))}
                            className="w-full"
                        />
                    </div>

                    {/* éœéŸ³æŒçºŒæ™‚é–“ */}
                    <div>
                        <label className="text-sm text-gray-700 block mb-1">
                            éœéŸ³æŒçºŒæ™‚é–“: {(silenceDuration / 1000).toFixed(1)}ç§’
                        </label>
                        <input
                            type="range"
                            min="500"
                            max="3000"
                            step="100"
                            value={silenceDuration}
                            onChange={(e) => setSilenceDuration(parseInt(e.target.value))}
                            className="w-full"
                        />
                    </div>

                    <div className="text-xs text-gray-600">
                        å•Ÿç”¨è‡ªå‹•æ–·å¥å¾Œï¼Œç³»çµ±æœƒåµæ¸¬éœéŸ³ä¸¦è‡ªå‹•ç™¼é€èªéŸ³ç‰‡æ®µ
                    </div>
                </div>
            </div>

            {/* ä½¿ç”¨èªªæ˜ */}
            <div className="bg-blue-50 border border-blue-200 rounded-lg p-3 text-xs text-gray-700">
                <div className="font-semibold mb-1">ä½¿ç”¨èªªæ˜</div>
                <ul className="space-y-1 list-disc list-inside">
                    <li>ç¾¤çµ„èªéŸ³ï¼šé»æ“Šã€Œé–‹å§‹ç™¼è©±ã€é–‹å§‹éŒ„éŸ³ï¼Œé»æ“Šã€Œåœæ­¢ç™¼è©±ã€çµæŸä¸¦ç™¼é€</li>
                    <li>ç§äººé€šè©±ï¼šè¼¸å…¥ç›®æ¨™ IDï¼Œé»æ“Šç™¼èµ·é€šè©±</li>
                    <li>é€šè©±ä¸­ç„¡æ³•ä½¿ç”¨ç¾¤çµ„ PTT</li>
                    <li>è‡ªå‹•æ–·å¥ï¼šå¯é–‹å•Ÿå¾Œç³»çµ±æœƒæ ¹æ“šéœéŸ³åµæ¸¬è‡ªå‹•åˆ†æ®µç™¼é€ï¼ˆé è¨­é—œé–‰ï¼‰</li>
                    <li>èªéŸ³è½‰æ–‡å­—ï¼šæ”¯æ´ç¹é«”ä¸­æ–‡å³æ™‚è½‰æ›ï¼ˆéœ€ç€è¦½å™¨æ”¯æ´ï¼‰</li>
                </ul>
            </div>
        </div>
    );
};

export default PTTAudio;
